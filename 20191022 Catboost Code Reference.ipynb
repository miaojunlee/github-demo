{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLD 10/22/2019\n",
    "\n",
    "## Introduction\n",
    "\n",
    "https://tech.yandex.com/catboost/\n",
    "    \n",
    "CatBoost is an open-source gradient boosting on decision trees library developed by Yandex researchers and engineers. It's the successor of the MatrixNet algorithm that is widely used within the industry for ranking tasks, forecasting and making recommendations. \n",
    "\n",
    "It's Accurate, Robust (reduces the need for extensive hyper-parameter tuning), Easy-to-use (integrated with scikitlearn), practical (uses categorical features directly and scalably) and **extensible (allows specifying custom loss functions)**\n",
    "\n",
    "Do not use OHE which reduces prediction accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CatBoostClassifier\n",
    "- CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/https-medium-com-talperetz24-mastering-the-new-generation-of-gradient-boosting-db04062a7ea2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm - Classic Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"classic_gradient_boosting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"gradient_tree.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Secret Sauce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catboost introduces two critical algorithmic advances - the implementation of **ordered boosting**, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for **processing categorical features**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature Handling - Ordered Target Statistic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying target statistic carelessly can result in target leakage. To fight this prediction shift CatBoost uses a more effective strategy. It relies on the ordering principle and is inspired by online learning algorithms which get training examples sequentially in time. In this setting, the values of TS for each example rely only on the observed history.\n",
    "To adapt this idea to a standard offline setting, Catboost introduces an artificial “time”— a random permutation σ1 of the training examples.\n",
    "Then, for each example, it uses all the available “history” to compute its Target Statistic.\n",
    "Note that, using only one random permutation, results in preceding examples with higher variance in Target Statistic than subsequent ones. To this end, CatBoost uses different permutations for different steps of gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature Handling - One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catboost uses a one-hot encoding for all the features with at most one_hot_max_size unique values. The default value is 2.\n",
    "\n",
    "<img src=\"catboost_one_hot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orederd Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost has two modes for choosing the tree structure, Ordered and Plain. **Plain mode** corresponds to a combination of the standard GBDT algorithm with an ordered Target Statistic. <br>\n",
    "In **Ordered mode** boosting we perform a random permutation of the training examples - σ2, and maintain n different supporting models - M1, . . . , Mn such that the model Mi is trained using only the first i samples in the permutation.\n",
    "At each step, in order to obtain the residual for j-th sample, we use the model Mj−1.\n",
    "Unfortunately, this algorithm is not feasible in most practical tasks due to the need of maintaining n different models, which increase the complexity and memory requirements by n times. Catboost implements a modification of this algorithm, on the basis of the gradient boosting algorithm, using one tree structure shared by all the models to be built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ordered_boosting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read catboost_playground "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost way of preparing dataset for model\n",
    "class Pool(data, \n",
    "           label=None,\n",
    "           cat_features=None,\n",
    "           column_description=None,\n",
    "           pairs=None,\n",
    "           delimiter='\\t',\n",
    "           has_header=False,\n",
    "           weight=None, \n",
    "           group_id=None,\n",
    "           group_weight=None,\n",
    "           subgroup_id=None,\n",
    "           pairs_weight=None\n",
    "           baseline=None,\n",
    "           feature_names=None,\n",
    "           thread_count=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool, cv \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "https://catboost.ai/docs/concepts/python-reference_parameters-list.html \n",
    "- **loss_function**: 'Logloss' for binomial classification, 'MultiClass' for more than 2 categories, 'RMSE' for regression \n",
    "- **iterations**: Num of trees to build\n",
    "- **depth**: Depth of the tree\n",
    "- **learning_rate**: default 0.03\n",
    "- **l2_leaf_reg**: Coefficient at the L2 regularization term of the cost function\n",
    "- **class_weights**: The value used as multiplier for the object weights. For imbalanced dataset classification the weight multiplier can be set to 1 for class 0 and (sum_negatives/sum_positives) for class 1. For instance, target rate of 2% then class_weights=[1,49] (result in bad performance when training on APost model with ConsumerView + OT Features)\n",
    "- **boosting_type**: Boosting scheme. \n",
    "    Possible values:\n",
    "        Ordered — Usually provides better quality on small datasets, but it may be slower than the Plain scheme. <br>\n",
    "        Plain — The classic gradient boosting scheme.\n",
    "\n",
    "- **border_count**: The number of splits for numerical features\n",
    "- **subsample**: Sample rate for bagging, default 0.66\n",
    "- **bagging_temperature**: This parameter is responsible for Bayesian bootstrap.\n",
    "Bayesian bootstrap is used by default in classification and regression modes. In ranking we use Bernoulli bootstrap by default.In bayesian bootstrap each object is assigned random weight. If bagging temperature is equal to 1 then weights are sampled from exponential distribution. If bagging temperature is equal to 0 then all weights are equal to 1. By changing this parameter from 0 to +infty you can controll intensity of the bootstrap.\n",
    "- **bootstrap_type**: Defines the method for sampling the weights of objects (Poisson, Bayesian, Bernoulli)\n",
    "- **random_strength**: This parameter helps to overcome overfitting of the model. When selecting a new split, each possible split gets a score (for example, by how much does adding this split improve the loss function on train). After that all scores are sorted and a split with the highest score is selected.\n",
    "The scores are not random. This parameter adds a normally distributed random variable to the score of the feature. It has zero mean and variance that is larger in the start of the training and decreases during the training. random_strength is the multiplier of the variance.\n",
    "- **min_data_in_leaf**: The minimum number of training samples in a leaf (support by GPU only)\n",
    "- **max_leaves**: Max # of trees in the resulting tree \n",
    "\n",
    "\n",
    "- **custom_metric**: metric values to output during training. These functions are not optimized and are displayed for informational purposes only. For classification, most used are Logloss, CrossEntropy, Precision, Recall, F1, Accuracy, and 'RMSE'/'MAE'/'MSLE' for regression https://catboost.ai/docs/concepts/loss-functions.html\n",
    "- **eval_metric** is for overfitting detection and best model selection. A user-defined function can also be set as the value. \n",
    "- **use_best_model**: True if a validation set is input\n",
    "- **nan_mode**: method for processing missing values ('Forbidden', 'Min' and 'Max')\n",
    "- **one_hot_max_size**: Use one-hot encoding for all categorical features with a number of different values less than or equal to the given parameter value.\n",
    "- **random_seed**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "catboost_params_space = [Real(1e-7, 1, prior='log-uniform', name='learning_rate'), \n",
    "                Integer(2, 10, name='max_depth'),\n",
    "                Real(0.5, 1.0, name='subsample'),\n",
    "                Real(0.5, 1.0, name='colsample_bylevel'),  \n",
    "                Integer(1, 10, name='gradient_iterations'), \n",
    "                Real(1.0, 16.0, name='scale_pos_weight'), \n",
    "                Real(0.0, 1.0, name='bagging_temperature'), \n",
    "                Integer(1, 20, name='random_strength'), \n",
    "                Integer(2, 25, name='one_hot_max_size'),\n",
    "                Real(1.0, 100, name='reg_lambda')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_train'] = np.random.uniform(0, 1,len(df)) <= .5\n",
    "train, val = df[df['is_train']==True], df[df['is_train']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# updated 03/05/2019\n",
    "\n",
    "def run_catboost(feature_set, \n",
    "                 iterations, \n",
    "                 depth, \n",
    "                 learning_rate, \n",
    "                 l2_leaf_reg, \n",
    "                 bagging_temperature, \n",
    "                 border_count, \n",
    "                 df, predict_var):\n",
    "    # Create two new dataframes, one with the training rows, one with the test rows\n",
    "#     train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "    # Show the number of observations for the test and training dataframes\n",
    "    print('Number of observations in the training data:', len(train))\n",
    "    print('Number of observations in the development data:', len(val))\n",
    "    print('Number of observations in the test data:',len(test))\n",
    "\n",
    "    X = train[feature_set]\n",
    "    y = train[target1].values\n",
    "\n",
    "    # CatBoost validates estimations against a subset of your training set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)  \n",
    "\n",
    "    categorical_feature_indices =np.where(X_train.dtypes==np.dtype('object'))[0]\n",
    "\n",
    "    model=CatBoostClassifier(loss_function='Logloss',\n",
    "                             iterations=iterations, \n",
    "                             depth=depth, \n",
    "                             learning_rate=learning_rate,\n",
    "                             l2_leaf_reg=l2_leaf_reg,\n",
    "#                              subsample=0.66, (cause error)\n",
    "                             bagging_temperature = bagging_temperature, \n",
    "                             border_count=border_count, \n",
    "                             random_strength=1,\n",
    "                             metric_period=50,\n",
    "                             od_type='Iter',\n",
    "                             od_wait=50,                           \n",
    "                             custom_metric=['Accuracy'],\n",
    "#                              custom_loss=['Accuracy'],\n",
    "                             eval_metric='AUC',\n",
    "#                              eval_metric=['Logloss','Accuracy'],\n",
    "                             use_best_model=True,\n",
    "                             thread_count=32,\n",
    "                             random_seed=42)\n",
    "\n",
    "    model.fit(X_train, y_train, cat_features=categorical_feature_indices, eval_set=(X_test, y_test), \n",
    "#               verbose=True,\n",
    "              plot=True)\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_true = y_test, y_pred = model.predict(X_test), labels=(0,1)))\n",
    "\n",
    "#     df[predict_var]  = model.predict_proba(df[feature_set])[:,1]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def charting(predict_var, df, feature_set, model):\n",
    "    train, validate, test = df[df['true_split']=='train'],df[df['true_split']=='val'],df[df['true_split']=='test']\n",
    "    \n",
    "    train.loc[:,predict_var]  = model.predict_proba(train[feature_set])[:,1]\n",
    "    validate.loc[:,predict_var]  = model.predict_proba(validate[feature_set])[:,1]\n",
    "    test.loc[:,predict_var]  = model.predict_proba(test[feature_set])[:,1]\n",
    "\n",
    "#     train = train.sort_values(predict_var, ascending=False)\n",
    "#     validate = validate.sort_values(predict_var, ascending=False)\n",
    "#     test = test.sort_values(predict_var, ascending=False)\n",
    "\n",
    "#     train.loc[:,'ntile']=range(len(train))\n",
    "#     validate.loc[:,'ntile']=range(len(validate))\n",
    "#     test.loc[:,'ntile']=range(len(test))\n",
    "\n",
    "    train.loc[:,'ntile']=pd.qcut(train['ntile'], 100, labels=False)\n",
    "    validate.loc[:,'ntile']=pd.qcut(validate['ntile'], 100, labels=False)\n",
    "    test.loc[:,'ntile']=pd.qcut(test['ntile'], 100, labels=False)\n",
    "    \n",
    "    june_train = train.groupby('ntile').agg({target1:['count','sum','mean']}).reset_index()\n",
    "    june_train.columns=['ntile','count','sum','avg_cr_train']\n",
    "\n",
    "    june_validate = validate.groupby('ntile').agg({target1:['count','sum','mean']}).reset_index()\n",
    "    june_validate.columns=['ntile','count','sum','avg_cr_val']\n",
    "\n",
    "    june_test = test.groupby('ntile').agg({target1:['count','sum','mean']}).reset_index()\n",
    "    june_test.columns=['ntile','count','sum','avg_cr_test']\n",
    "    \n",
    "    train_val_test = pd.concat([june_train, june_validate['avg_cr_val'], june_test['avg_cr_test']], axis=1)\n",
    "    \n",
    "    print(train_val_test)\n",
    "    train_val_test[['avg_cr_train','avg_cr_val','avg_cr_test']].plot(figsize=(10,8))\n",
    "    \n",
    "    return train_val_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two group\n",
    "def charting(predict_var, df, feature_set, model):\n",
    "    train, validate = df2[df2['is_train']==True], df2[df2['is_train']==False]\n",
    "    \n",
    "    train.loc[:,predict_var]  = model.predict_proba(train[feature_set])[:,1]\n",
    "    validate.loc[:,predict_var]  = model.predict_proba(validate[feature_set])[:,1]\n",
    "\n",
    "    train = train.sort_values(predict_var, ascending=False)\n",
    "    validate = validate.sort_values(predict_var, ascending=False)\n",
    "\n",
    "    train.loc[:,'ntile']=range(len(train))\n",
    "    validate.loc[:,'ntile']=range(len(validate))\n",
    "\n",
    "    train.loc[:,'ntile']=pd.qcut(train['ntile'], 100, labels=False)\n",
    "    validate.loc[:,'ntile']=pd.qcut(validate['ntile'], 100, labels=False)\n",
    "    \n",
    "    june_train = train.groupby('ntile').agg({target1:['count','sum','mean']}).reset_index()\n",
    "    june_train.columns=['ntile','count','sum','avg_cr_train']\n",
    "\n",
    "    june_validate = validate.groupby('ntile').agg({target1:['count','sum','mean']}).reset_index()\n",
    "    june_validate.columns=['ntile','count','sum','avg_cr_val']\n",
    "  \n",
    "    train_val_test = pd.concat([june_train, june_validate['avg_cr_val']], axis=1)\n",
    "    \n",
    "    print(train_val_test)\n",
    "    train_val_test[['avg_cr_train','avg_cr_val']].plot(figsize=(10,8))\n",
    "    \n",
    "    return train_val_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations=1500\n",
    "depth=6\n",
    "learning_rate=0.03\n",
    "l2_leaf_reg=80\n",
    "border_count=10\n",
    "bagging_temperature=10\n",
    "\n",
    "model1, df = run_catboost(all_features, \n",
    "                          iterations, \n",
    "                          depth, \n",
    "                          learning_rate, \n",
    "                          l2_leaf_reg, \n",
    "                          bagging_temperature, \n",
    "                          border_count, \n",
    "                          df, \n",
    "                          'sale_hat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model1.get_best_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format='{:,.2f}'.format\n",
    "feature_importances = list(zip(df[all_features], model1.feature_importances_))\n",
    "feature_importances = pd.DataFrame(feature_importances, columns=['feature_name', 'importance'])\n",
    "feature_importances.set_index('feature_name').sort_values(by='importance',ascending=False)\n",
    "# feature_importances.set_index('feature_name').sort_values(by='importance',ascending=True).plot(kind='barh', color='blue', alpha=0.5, fontsize=10, figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_val_test = charting('sale_hat', df2, all_features, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top30 = list(feature_importances.sort_values(by='importance',ascending=False)['feature_name'].head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_data = cv(model.get_params(),\n",
    "             Pool(X_train,y_train,cat_features=categorical_feature_indices),\n",
    "             fold_count=3,\n",
    "             plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('the best cv accuracy is :{}'.format(np.max(cv_data[\"b'Accuracy'_test_avg\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('the test accuracy is :{:.6f}'.format(accuracy_score(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Object Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MaxRPS'].fillna(0, inplace=True)\n",
    "df['weight']=np.log(df['MaxRPS']+1)\n",
    "df['weight2']=df['MaxRPS'].apply(lambda x:1.5 if x>50 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df[df['is_train']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "for i in ['MarketingChannel',\n",
    " 'mobile_browser',\n",
    " 'brand_name',\n",
    " 'PaymentMethod',\n",
    " 'device_os',\n",
    " 'DeviceGroup',\n",
    " 'ReasonForCheckingCredit',\n",
    " 'IsMobileBrowser',\n",
    " 'PoliticalPersona',\n",
    " 'Mosaic Household',\n",
    " 'State Abbreviation',\n",
    " 'Mosaic ZIP4',\n",
    " 'IsDesktopBrowser',\n",
    " 'SRVY:HH Lifestyl:Buying:Sports Related',\n",
    " 'IsTablet',\n",
    " 'MobileUsers',\n",
    " 'EducationModel',\n",
    " 'City Name',\n",
    " 'Estimated Household Income Range Code V6',\n",
    " 'Mosaic Global ZIP4',\n",
    " 'ZIP Locality',\n",
    " 'Household Composition',\n",
    " 'SRVY:HH Lifestyl:Credit Cards:Other CardPremium']:\n",
    "    df[i]=le.fit_transform(df[i].astype(str))\n",
    "    df[i]=df[i].astype(str)\n",
    "    \n",
    "X = train[top50]\n",
    "y = train['Sale'].values\n",
    "\n",
    "    # CatBoost validates estimations against a subset of your training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)  \n",
    "\n",
    "categorical_feature_indices =np.where(X_train.dtypes==np.dtype('object'))[0]\n",
    "\n",
    "import catboost as cat\n",
    "from catboost import Pool\n",
    "train_set = cat.Pool(data=X_train, label=y_train, cat_features=categorical_feature_indices, weight=df.loc[X_train.index,'weight2'])\n",
    "test_set  = cat.Pool(data=X_test, label=y_test, cat_features=categorical_feature_indices, weight=df.loc[X_test.index,'weight2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5=CatBoostClassifier(loss_function='Logloss',\n",
    "                             iterations=2000, \n",
    "                             depth=6, \n",
    "                             learning_rate=0.03,\n",
    "                             l2_leaf_reg=80,\n",
    "#                              subsample=0.66,\n",
    "                             bagging_temperature = 10,\n",
    "                             border_count=10, \n",
    "                             random_strength=1,\n",
    "                             metric_period=50,\n",
    "                             od_type='Iter',\n",
    "                             od_wait=50,                           \n",
    "#                              custom_metric=['Accuracy'],\n",
    "# #                              custom_loss=['Accuracy'],\n",
    "#                              eval_metric='AUC',\n",
    "                             use_best_model=True,\n",
    "                             thread_count=32,\n",
    "                             random_seed=42)\n",
    "\n",
    "model5.fit(train_set, eval_set=test_set, \n",
    "#            verbose=True,\n",
    "           plot=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost & Bayesian Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical features need to convert into numeric format and set them to object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=train[cr_top_30]\n",
    "y=train[target1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.isnull().sum() # no NA in cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features_short = [i for i in X.columns if X[i].dtypes==np.dtype('object')]\n",
    "num_features_short = [i for i in X.columns if X[i].dtypes!=np.dtype('object')]\n",
    "print(cat_features_short)\n",
    "print(num_features_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "for i in cat_features_short:\n",
    "    X[i+'_le'] = le.fit_transform(X[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert it back to object\n",
    "for i in ['MarketingChannel_le', 'DeviceType_le', 'ScoreRange_le', 'DeviceOS_le',\n",
    "       'LastReasonForCheckingCredit_le', 'WorstPayStatus_le',\n",
    "       'BrowserFamily_le']:\n",
    "    X[i]=X[i].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cr_top30_le = num_features_short + ['MarketingChannel_le', 'DeviceType_le', 'ScoreRange_le', 'DeviceOS_le',\n",
    "       'LastReasonForCheckingCredit_le', 'WorstPayStatus_le',\n",
    "       'BrowserFamily_le']\n",
    "\n",
    "print(cr_top30_le)\n",
    "print(len(cr_top30_le))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = train[cr_top30_le]\n",
    "y = train[target]\n",
    "\n",
    "# CatBoost validates estimations against a subset of your training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, random_state=1234)  \n",
    "\n",
    "categorical_feature_indices =np.where(X_train.dtypes==np.dtype('object'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ris=Pool(X_train,label=y_train,cat_features=categorical_feature_indices)\n",
    "test_ris=Pool(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def catcv(iterations, depth, l2_leaf_reg, bagging_temperature,border_count):\n",
    "    params={\n",
    "            'iterations':int(iterations),\n",
    "            'depth':int(depth),\n",
    "            'l2_leaf_reg':l2_leaf_reg,\n",
    "            'bagging_temperature':bagging_temperature,\n",
    "            'border_count':int(border_count)\n",
    "        }\n",
    "    params['loss_function']='Logloss'\n",
    "    params['eval_metric']='AUC'\n",
    "    val = cv(\n",
    "             train_ris,\n",
    "             params,\n",
    "             iterations=5\n",
    "            ).mean()\n",
    "    return val['test-AUC-mean']\n",
    "\n",
    "bayesian= {\n",
    "            'iterations':(200,1000),\n",
    "            # max depth is 16\n",
    "            'depth':(1,16),\n",
    "            'l2_leaf_reg':(1,100),\n",
    "            'bagging_temperature':(0,100),\n",
    "            'border_count':(1,255)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "bayesian_search =BayesianOptimization(catcv,bayesian)\n",
    "\n",
    "bayesian_search.maximize(n_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayesian_search.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayesian_params=bayesian_search.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayesian_params['loss_function']='Logloss'\n",
    "bayesian_params['eval_metric']='AUC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_params={\n",
    "            'iterations':int(bayesian_params['iterations']),\n",
    "            'depth':int(bayesian_params['depth']),\n",
    "            'l2_leaf_reg':bayesian_params['l2_leaf_reg'],\n",
    "            'bagging_temperature':bayesian_params['bagging_temperature'],\n",
    "            'border_count':int(bayesian_params['border_count'])\n",
    "        }\n",
    "final_params['loss_function']='Logloss'\n",
    "final_params['eval_metric']='AUC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayesian_final_classifier=cat.train(pool_train_redhat,final_params,iterations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Catboost w GridSearch & CV Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from paramsearch import paramsearch\n",
    "from itertools import product,chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = X_train.copy()\n",
    "train_label = y_train.copy()\n",
    "\n",
    "test_set = X_test.copy()\n",
    "test_label = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'depth':[3,1,2,6,4,5,7,8,9,10],\n",
    "          'iterations':[250,100,500,1000],\n",
    "          'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n",
    "          'l2_leaf_reg':[3,1,5,10,100],\n",
    "          'border_count':[32,5,10,20,50,100,200],\n",
    "#           'ctr_border_count':[50,5,10,20,100,200],\n",
    "          'thread_count':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossvaltest(params,train_set,train_label,cat_dims,n_splits=3):\n",
    "    kf = KFold(n_splits=n_splits,shuffle=True) \n",
    "    \n",
    "    res = []\n",
    "    for train_index, test_index in kf.split(train_set):\n",
    "        train = train_set.iloc[train_index,:]\n",
    "        test = train_set.iloc[test_index,:]\n",
    "\n",
    "        labels = train_label.ix[train_index]\n",
    "        test_labels = train_label.ix[test_index]\n",
    "\n",
    "        clf = cb.CatBoostClassifier(**params)\n",
    "        clf.fit(train, np.ravel(labels), cat_features=cat_dims)\n",
    "\n",
    "        res.append(np.mean(clf.predict(test)==np.ravel(test_labels)))\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def catboost_param_tune(params,train_set,train_label,cat_dims=None,n_splits=3):\n",
    "    ps = paramsearch(params)\n",
    "    # search 'border_count', 'l2_leaf_reg' etc. individually \n",
    "    #   but 'iterations','learning_rate' together\n",
    "    for prms in chain(ps.grid_search(['border_count']),\n",
    "#                       ps.grid_search(['ctr_border_count']),\n",
    "                      ps.grid_search(['l2_leaf_reg']),\n",
    "                      ps.grid_search(['iterations','learning_rate']),\n",
    "                      ps.grid_search(['depth'])):\n",
    "        res = crossvaltest(prms,train_set,train_label,cat_dims,n_splits)\n",
    "        # save the crossvalidation result so that future iterations can reuse the best parameters\n",
    "        ps.register_result(res,prms)\n",
    "        print(res,prms,'best:',ps.bestscore(),ps.bestparam())\n",
    "    return ps.bestparam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train classifier with tuned parameters    \n",
    "clf = cb.CatBoostClassifier(**bestparams)\n",
    "clf.fit(train_set, np.ravel(train_label), cat_features=cat_dims)\n",
    "res = clf.predict(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search (internal metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(varname):\n",
    "\n",
    "    train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "\n",
    "    # Sort the dataframe by the value you want\n",
    "    train = train.sort_values(varname, ascending=False)\n",
    "    test = test.sort_values(varname, ascending=False)\n",
    "\n",
    "    # Create a unique row number on the sorted dataframe\n",
    "    train['ntile'] = range(len(train))\n",
    "    test['ntile'] = range(len(test))\n",
    "\n",
    "    # Use the Pandas qcut method to divide the dataset up into n ntiles\n",
    "    train['ntile'] = pd.qcut(train['ntile'], 100, labels=False)\n",
    "    test['ntile'] = pd.qcut(test['ntile'], 100, labels=False)\n",
    "\n",
    "    # Create a new dataframe containing your summary metrics; rename the columns\n",
    "    joTrain = train.groupby(['ntile']).agg({'RIS_Flag_All':['count','sum'], 'RIS_All':['sum'], 'VisaTxnAmt_All':['sum'],\n",
    "                                            'RIS_Flag_180D':['sum'], 'RIS_180D':['sum'], 'VisaTxnAmt_180D':['sum']\n",
    "                                            }).reset_index()\n",
    "    joTrain.columns = [\"_\".join(x) for x in joTrain.columns.ravel()]\n",
    "\n",
    "    joTest = test.groupby(['ntile']).agg({'RIS_Flag_All':['count','sum'], 'RIS_All':['sum'], 'VisaTxnAmt_All':['sum'],\n",
    "                                            'RIS_Flag_180D':['sum'], 'RIS_180D':['sum'], 'VisaTxnAmt_180D':['sum']\n",
    "                                           }).reset_index()\n",
    "    joTest.columns = [\"_\".join(x) for x in joTest.columns.ravel()] \n",
    "    \n",
    "    performance=[]\n",
    "    train_RIS_180D_sum = joTrain.loc[joTrain.ntile_<=9]['RIS_180D_sum'].sum()\n",
    "    train_VISA_180D_sum = joTrain.loc[joTrain.ntile_<=9]['VisaTxnAmt_180D_sum'].sum()\n",
    "    train_ris_pct = train_RIS_180D_sum/74289\n",
    "    train_rev_pct = train_VISA_180D_sum/4486015\n",
    "\n",
    "    test_RIS_180D_sum = joTest.loc[joTest.ntile_<=9]['RIS_180D_sum'].sum()\n",
    "    test_VISA_180D_sum = joTest.loc[joTest.ntile_<=9]['VisaTxnAmt_180D_sum'].sum()\n",
    "    test_ris_pct = test_RIS_180D_sum/70152\n",
    "    test_rev_pct = test_VISA_180D_sum/3801526\n",
    "\n",
    "    performance.append(('{:,.2%}'.format(train_ris_pct), '{:,.2%}'.format(train_rev_pct),'{:,.2f}'.format(train_VISA_180D_sum/train_RIS_180D_sum), \n",
    "                        '{:,.2%}'.format(test_ris_pct),  '{:,.2%}'.format(test_rev_pct), '{:,.2f}'.format(test_VISA_180D_sum/test_RIS_180D_sum )))\n",
    "    \n",
    "    performance_df = pd.DataFrame(performance, columns=['Train_RIS_PCT', 'Train_Rev_PCT', 'Train_RIS_Raito',\n",
    "                                                        'Test_RIS_PCT', 'Test_Rev_PCT', 'Test_RIS_Raito'])\n",
    "\n",
    "    return performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import catboost \n",
    "from catboost import Pool, cv, CatBoostClassifier, CatboostIpythonWidget\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def run_catboost(feature_set, iterations, depth, learning_rate, l2_leaf_reg, bagging_temperature, predict_var):\n",
    "    # Create two new dataframes, one with the training rows, one with the test rows\n",
    "    train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "\n",
    "    # Show the number of observations for the test and training dataframes\n",
    "    print('Number of observations in the training data:', len(train))\n",
    "    print('Number of observations in the test data:',len(test))\n",
    "\n",
    "    X = train[feature_set]\n",
    "    y = train[target]\n",
    "\n",
    "    # CatBoost validates estimations against a subset of your training set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)  \n",
    "\n",
    "    categorical_feature_indices =np.where(X_train.dtypes==np.dtype('object'))[0]\n",
    "    \n",
    "    result = pd.DataFrame() # create an empty dataframe before the loop\n",
    "    for i in iterations: \n",
    "        for d in depth:\n",
    "            for lr in learning_rate:\n",
    "                for reg in l2_leaf_reg:\n",
    "                    for b in bagging_temperature:\n",
    "                        model=CatBoostClassifier(\n",
    "                             iterations=i, \n",
    "                             depth=d, \n",
    "                             learning_rate=lr,\n",
    "                             l2_leaf_reg=reg,\n",
    "                             od_type='Iter',\n",
    "                             od_wait=50,\n",
    "                             loss_function='Logloss',\n",
    "#                              metric_period=50,\n",
    "                             custom_loss=['Accuracy'],\n",
    "                             eval_metric='AUC',\n",
    "                             thread_count=32,\n",
    "                             random_seed=42)\n",
    "                        model.fit(X_train, y_train, cat_features=categorical_feature_indices, eval_set=(X_test, y_test), verbose=False,plot=False)\n",
    "                        df[predict_var]  = model.predict_proba(df[feature_set])[:,1]\n",
    "\n",
    "                        performance_df = eval_model(predict_var)\n",
    "                        performance_df['iteration']=i\n",
    "                        performance_df['depth']=d\n",
    "                        performance_df['learning_rate']=lr\n",
    "                        performance_df['l2_leaf_reg']=reg\n",
    "                        performance_df['bagging_temperature']=b\n",
    "                #         result.append(performance_df)\n",
    "                        result = pd.concat([result, performance_df], axis=0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations=[500, 600,700,800,1000]\n",
    "depth=[3,4,5,6,7,8]\n",
    "learning_rate=[0.005,0.01,0.03,0.05]\n",
    "l2_leaf_reg=[5,10,20,30,50]\n",
    "bagging_temperature=[1,5,10]\n",
    "\n",
    "result = run_catboost(good_features, iterations, depth, learning_rate, l2_leaf_reg, bagging_temperature, 'ris_hat2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# updated 2019/02/05\n",
    "train, validate, test = df2[df2['true_split']=='train'],df2[df2['true_split']=='val'],df2[df2['true_split']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[all_features]\n",
    "y = train['Day180Revenue']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=1234)\n",
    "\n",
    "X_test = test[all_features]\n",
    "y_test = test['Day180Revenue']\n",
    "\n",
    "categorical_feature_indices =np.where(X_train.dtypes==np.dtype('object'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn way\n",
    "# no missing data in the target label is allowed\n",
    "model=cat.CatBoostRegressor(iterations=1000, \n",
    "                            learning_rate=0.03,\n",
    "                            depth=6,\n",
    "                            l2_leaf_reg = 60, \n",
    "                            bagging_temperature=10,\n",
    "                            border_count = 10, \n",
    "                            eval_metric='RMSE', # does not support MSE/MAE\n",
    "                            random_seed=123,   \n",
    "                            od_type='Iter', #overfit detector wait type: iteration\n",
    "                            metric_period=50,\n",
    "                            od_wait=20 #overfit detector wait\n",
    "                               )\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=(X_val,y_val),\n",
    "          cat_features=categorical_feature_indices,\n",
    "          use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import catboost as cat\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return round(np.sqrt(mean_squared_error(y_true, y_pred)), 5)\n",
    "\n",
    "def run_catboost(X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                 iterations,\n",
    "                 learning_rate,\n",
    "                 depth,\n",
    "                 l2_leaf_reg,\n",
    "                 bagging_temperature,\n",
    "                 border_count \n",
    "                ):\n",
    "    \n",
    "\n",
    "#     categorical_feature_indices =np.where(X_train.dtypes==np.dtype('object'))[0]\n",
    "\n",
    "    train_set=cat.Pool(data=X_train, label=y_train, cat_features=categorical_feature_indices)\n",
    "    eval_set=cat.Pool(data=X_val, label=y_val, cat_features=categorical_feature_indices)\n",
    "    \n",
    "    model=cat.CatBoostRegressor(iterations=iterations, \n",
    "                               learning_rate=learning_rate,\n",
    "                               depth=depth,\n",
    "                               l2_leaf_reg = l2_leaf_reg, \n",
    "                               bagging_temperature=bagging_temperature,\n",
    "                               border_count = border_count, \n",
    "                               eval_metric='RMSE', # does not support MSE/MAE\n",
    "                               random_seed=123,   \n",
    "                               od_type='Iter', #overfit detector wait type: iteration\n",
    "                               metric_period=50,\n",
    "                               od_wait=20 #overfit detector wait\n",
    "                               )\n",
    "    \n",
    "    model.fit(train_set, \n",
    "             eval_set=eval_set,\n",
    "             use_best_model=True,\n",
    "             verbose=50\n",
    "             )\n",
    "    \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred_submit = model.predict(X_test)\n",
    "    \n",
    "    print(f\"CatB: RMSE val: {rmse(y_val, y_pred_val)} - RMSE train: {rmse(y_train, y_pred_train)}\")\n",
    "#     print(model.get_best_score())\n",
    "    print('test: RMSE ', rmse(y_test, y_pred_submit))\n",
    "    \n",
    "    print(model.get_best_iteration())\n",
    "    \n",
    "    return y_pred_submit, model         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_submit, model   = run_catboost(X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "                                      iterations=1000, \n",
    "                                      learning_rate=0.03,\n",
    "                                      depth=6,\n",
    "                                      l2_leaf_reg=60,\n",
    "                                      bagging_temperature=10,\n",
    "                                      border_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(list(zip(X_train[all_features], model.feature_importances_)))\n",
    "feature_importances.columns=['Feature Name', 'IMP']\n",
    "\n",
    "pd.options.display.float_format='{:,.3}'.format\n",
    "feature_importances.sort_values(by='IMP', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def charting(predict_var, feature_set, df, target):\n",
    "    train, validate, test = df[df['true_split']=='train'],df[df['true_split']=='val'],df[df['true_split']=='test']\n",
    "    \n",
    "    train[predict_var]  = model.predict(train[feature_set])\n",
    "    validate[predict_var]  = model.predict(validate[feature_set])\n",
    "    test[predict_var]  = model.predict(test[feature_set])\n",
    "\n",
    "    train = train.sort_values(predict_var, ascending=False)\n",
    "    validate = validate.sort_values(predict_var, ascending=False)\n",
    "    test = test.sort_values(predict_var, ascending=False)\n",
    "\n",
    "    train['ntile']=range(len(train))\n",
    "    validate['ntile']=range(len(validate))\n",
    "    test['ntile']=range(len(test))\n",
    "\n",
    "    train['ntile']=pd.qcut(train['ntile'], 100, labels=False)\n",
    "    validate['ntile']=pd.qcut(validate['ntile'], 100, labels=False)\n",
    "    test['ntile']=pd.qcut(test['ntile'], 100, labels=False)\n",
    "    \n",
    "    june_train = train.groupby('ntile').agg({target:['count','mean']}).reset_index()\n",
    "    june_train.columns=['ntile','count','avg_revenue_train']\n",
    "\n",
    "    june_validate = validate.groupby('ntile').agg({target:['count','mean']}).reset_index()\n",
    "    june_validate.columns=['ntile','count','avg_revenue_val']\n",
    "\n",
    "    june_test = test.groupby('ntile').agg({target:['count','mean']}).reset_index()\n",
    "    june_test.columns=['ntile','count','avg_revenue_test']\n",
    "    \n",
    "    train_val_test = pd.concat([june_train, june_validate['avg_revenue_val'], june_test['avg_revenue_test']], axis=1)\n",
    "    return train_val_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_val_test = charting('rev_hat',all_features,df2,'Day180Revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two group\n",
    "df['RPSMax_hat'] = model.predict(df[modeling_features])\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "\n",
    "print(\"Avg RPS in training:\", train['RPSMax'].mean(), train['RPSMax_hat'].mean())\n",
    "print(\"Avg RPS in test:\", test['RPSMax'].mean(), test['RPSMax_hat'].mean())\n",
    "\n",
    "train = train.sort_values('RPSMax_hat', ascending=False)\n",
    "test = test.sort_values('RPSMax_hat', ascending=False)\n",
    "\n",
    "# Create a unique row number on the sorted dataframe\n",
    "train['ntile'] = range(len(train))\n",
    "test['ntile'] = range(len(test))\n",
    "\n",
    "# Use the Pandas qcut method to divide the dataset up into n ntiles\n",
    "train['ntile'] = pd.qcut(train['ntile'], 100, labels=False)\n",
    "test['ntile'] = pd.qcut(test['ntile'], 100, labels=False)\n",
    "\n",
    "# Create a new dataframe containing your summary metrics; rename the columns\n",
    "joTrain = train.groupby(['ntile']).agg({'RPSMax':['mean']}).reset_index()\n",
    "joTrain.columns = [\"_\".join(x) for x in joTrain.columns.ravel()]\n",
    "\n",
    "joTest = test.groupby(['ntile']).agg({'RPSMax':['mean']}).reset_index()\n",
    "joTest.columns = [\"_\".join(x) for x in joTest.columns.ravel()]\n",
    "\n",
    "train_test_compare = pd.merge(left=joTrain, right=joTest, on='ntile_', suffixes=('_Train', '_Test'), how='inner')\n",
    "rps_result = train_test_compare[['ntile_', 'RPSMax_mean_Train', \"RPSMax_mean_Test\"]]\n",
    "rps_result.set_index('ntile_')\n",
    "rps_result[['RPSMax_mean_Train', \"RPSMax_mean_Test\"]].plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostRegressor & Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# updated 2019/02/04\n",
    "categorical_feature_indices =np.where(X_train.dtypes==np.dtype('object'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return round(np.sqrt(mean_squared_error(y_true, y_pred)), 5)\n",
    "\n",
    "def rand_cat(train_X, train_y):\n",
    "    random= { \"iterations\"                  : sp_randint (1, 2000),\n",
    "              \"learning_rate\"               : [0.0001, 0.001, 0.003,0.005,0.01,0.03,0.05],\n",
    "              \"depth\"                       : np.linspace(4,16,1),\n",
    "              \"l2_leaf_reg\"                 : np.linspace(0.1,10,100),\n",
    "              \"bagging_temperature\"         : np.linspace(0.1,2,20),\n",
    "              \"od_wait\"                     : [10,50,100,150],\n",
    "             \"cat_features\": categorical_feature_indices\n",
    "            }\n",
    "    cat_regressor = cat.CatBoostRegressor(od_type='Iter',\n",
    "                                          metric_period = 50,\n",
    "                                          od_wait=20\n",
    "                                         )\n",
    "    \n",
    "    random_search =RandomizedSearchCV(cat_regressor, \n",
    "                                      param_distributions=random, \n",
    "                                      scoring = \"neg_mean_squared_error\",\n",
    "                                      n_iter=20, \n",
    "                                      cv = 5, \n",
    "                                      n_jobs = -1,\n",
    "                                      verbose = True)\n",
    "\n",
    "\n",
    "    random_search.fit(train_X,train_y)\n",
    "    return random_search.best_params_, random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search.best_params_, random_search.best_estimator_ = rand_cat(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostRegressor & Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import catboost as cat\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product, chain\n",
    "from tqdm import tqdm\n",
    "\n",
    "temp_prms = {'loss_function':'RMSE',\n",
    "            'iterations': 500,\n",
    "            'learning_rate': 0.05,\n",
    "            'l2_leaf_reg':3,\n",
    "            'depth':10,\n",
    "            'bagging_temperature':0.8,\n",
    "            'eval_metric':'RMSE'\n",
    "            }\n",
    "\n",
    "def cat_cross_cv(X, y,prms, cat_features, fold_count):\n",
    "    score = []\n",
    "    \n",
    "    train_set=cat.Pool(data = X, label=y, cat_features=cat_features)\n",
    "\n",
    "    rmse = cat.cv(pool = train_set, \n",
    "                params = temp_prms, \n",
    "                iterations= 500, \n",
    "                fold_count = fold_count,\n",
    "                partition_random_seed = 123,\n",
    "                verbose = True,\n",
    "                as_pandas = True,\n",
    "                metric_period = 50,\n",
    "                early_stopping_rounds = 20)\n",
    "    \n",
    "    score.append(np.mean(rmse['test-Logloss-mean']))\n",
    "    return np.mean(score)\n",
    "    \n",
    "score = cat_cross_cv(X_train, y_train,prms = temp_prms, cat_features = cat_col_index, fold_count = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save & Load Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(r'F:\\Projects\\June\\RIS\\20180808_RIS_catboost_model.dump') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier()\n",
    "model.load_model(r'F:\\Projects\\June\\RIS\\20180816_RIS_catboost_model_w_totalbalance.dump') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking model version\n",
    "print(catboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoost supports training on GPUs\n",
    "\n",
    "model = CatBoostClassifier(iterations=1000, \n",
    "                           task_type = \"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Skewed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxcox transformation\n",
    "# log transformation\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p\n",
    "rps['rps_boxcox']=boxcox1p(rps['MaxRPS'],0.25)\n",
    "rps['rps_boxcox'].plot(kind='hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://github.com/groverpr/Machine-Learning/tree/master/notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Feature Importance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/deep-dive-into-catboost-functionalities-for-model-interpretation-7cdef669aeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ModelAnalysis.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cb = CatBoostRegressor() <br>\n",
    "cb.get_feature_importance(type= \"___\")\n",
    "\n",
    " \"type\" possible values:\n",
    "  - PredictionValuesChange\n",
    "  - LossFunctionChange\n",
    "  - FeatureImportance: \n",
    "      PredictionValuesChange for non-ranking metrics and LossFunctionChange for ranking metrics\n",
    "  - ShapValues: \n",
    "      Calculate SHAP Values for every object\n",
    "  - Interaction: \n",
    "      Calculate pairwise score between every feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PredictionValuesChange** <br>\n",
    "Pros: It is cheap to compute as you don’t have to do multiple training or testing and you will not be storing any extra information. You will get normalized values as the ouput (all the importances will add up to 100). <br>\n",
    "Cons: It may give misleading results for ranking objectives, it might put groupwise features into the top, even though they have a little influence on the resulting loss value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LossFunctionChange** <br>\n",
    "To get this feature importance, catboost simply takes the difference between the metric (Loss function) obtained using the model in normal scenario (when we include the feature) and model without this feature (model is built approximately using the original model with this feature removed from all the trees in the ensemble). Higher the difference, the more important the feature is. It is not clearly mentioned in catboost docs how we find the model without feature. <br>\n",
    "\n",
    "Pros & Cons: This works well for most type of problems unlike predictionvalueschange where you can get misleading results for ranking problems, at the same time, it is computationally heavy ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SHAP Values**\n",
    "\n",
    "SHAP stands for SHAP (SHapley Additive exPlanations) \n",
    "\n",
    "https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d \n",
    "    \n",
    "It is the average of the marginal contributions across all permutations. It offers object-level contributions of features and overall feature importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairwise Feature Importance \n",
    "\n",
    "With the Interaction parameter, you can find the strength of a pair of features (importance of two features together).\n",
    "\n",
    "<img src=\"pairwise_feature_imp.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline \n",
    "import catboost\n",
    "from catboost import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import shap\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18\n"
     ]
    }
   ],
   "source": [
    "X = train[ot_features]\n",
    "y = train['Sale'].values\n",
    "categorical_feature_indices =np.where(X.dtypes==np.dtype('object'))[0]\n",
    "\n",
    "from catboost import Pool\n",
    "pool= Pool(X,label=y, cat_features=categorical_feature_indices)\n",
    "model6.get_feature_importance(pool,type='PredictionValuesChange', prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.get_feature_importance(pool,type='LossFunctionChange', prettified=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
